\begin{center}
    \Large{\textbf{Аннотация}}
\end{center}

При построении модели машинного обучения неизбежно возникает проблема сбора данных для ее обучения.
Зачастую, по той или иной причине, естественное требование при этом~--- минимизировать количество таких данных.
В настоящей работе исследуется задача определения достаточного размера выборки. 
Рассматривается проблема определения достаточного размера выборки без постановки статистической гипотезы о распределении параметров модели. 

Предлагаются два подхода к определению достаточного размера выборки по значениям функции правдоподобия на подвыборках с возвращением. 
Эти подходы основываются на эвристиках о поведении функции правдоподобия при большом количестве объектов в выборке. 
Предлагаются два подхода к определению достаточного размера выборки на основании близости апостериорных распределений параметров модели на схожих подвыборках. 
Доказывается корректность представленных подходов при определенных ограничениях на используемую модель. 
Доказываются теоремы о моментах и полном байесовском прогнозе предельного апостериорного распределения параметров в модели линейной регрессии.
Предлагается метод прогнозирования функции правдоподобия в случае недостаточного размера выборки. 
Проводится вычислительный эксперимент для анализа свойств предложенных методов.